#!/usr/bin/env python3
"""í•œêµ­íˆ¬ìì¦ê¶Œ ì¢…ëª© ê²€ìƒ‰ ìŠ¤í¬ë¦½íŠ¸ (KRX ì£¼ì‹ + ETF + ì§€ìˆ˜ ì§€ì›)"""

import argparse
import json
import sys
from pathlib import Path
from datetime import datetime, timedelta

try:
    import FinanceDataReader as fdr
except ImportError:
    fdr = None

# ìºì‹œ íŒŒì¼ ê²½ë¡œ
CACHE_DIR = Path(__file__).parent / ".cache"
CACHE_FILE = CACHE_DIR / "krx_all.json"
CACHE_EXPIRY_HOURS = 24

# ì£¼ìš” ì§€ìˆ˜ ì •ë³´
INDICES = {
    "ì½”ìŠ¤í”¼": {"symbol": "KS11", "name": "KOSPI ì¢…í•©"},
    "kospi": {"symbol": "KS11", "name": "KOSPI ì¢…í•©"},
    "ì½”ìŠ¤ë‹¥": {"symbol": "KQ11", "name": "KOSDAQ ì¢…í•©"},
    "kosdaq": {"symbol": "KQ11", "name": "KOSDAQ ì¢…í•©"},
    "ì½”ìŠ¤í”¼200": {"symbol": "KS200", "name": "KOSPI 200"},
    "kospi200": {"symbol": "KS200", "name": "KOSPI 200"},
    "ë‹¤ìš°": {"symbol": "DJI", "name": "ë‹¤ìš°ì¡´ìŠ¤ ì‚°ì—…í‰ê· "},
    "ë‹¤ìš°ì¡´ìŠ¤": {"symbol": "DJI", "name": "ë‹¤ìš°ì¡´ìŠ¤ ì‚°ì—…í‰ê· "},
    "ë‚˜ìŠ¤ë‹¥": {"symbol": "IXIC", "name": "ë‚˜ìŠ¤ë‹¥ ì¢…í•©"},
    "nasdaq": {"symbol": "IXIC", "name": "ë‚˜ìŠ¤ë‹¥ ì¢…í•©"},
    "s&p500": {"symbol": "S&P500", "name": "S&P 500"},
    "s&p": {"symbol": "S&P500", "name": "S&P 500"},
    "ë‹ˆì¼€ì´": {"symbol": "N225", "name": "ë‹ˆì¼€ì´ 225"},
    "í•­ì…": {"symbol": "HSI", "name": "í•­ì… ì§€ìˆ˜"},
    "ìƒí•´": {"symbol": "SSEC", "name": "ìƒí•´ ì¢…í•©"},
}


def load_cache() -> dict | None:
    """ìºì‹œëœ ë°ì´í„° ë¡œë“œ"""
    if not CACHE_FILE.exists():
        return None

    try:
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)

        cached_time = datetime.fromisoformat(data.get("timestamp", "2000-01-01"))
        if datetime.now() - cached_time > timedelta(hours=CACHE_EXPIRY_HOURS):
            return None

        return data
    except Exception:
        return None


def save_cache(data: dict) -> None:
    """ë°ì´í„° ìºì‹œ ì €ì¥"""
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    data["timestamp"] = datetime.now().isoformat()
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def fetch_all_listings() -> dict:
    """KRX ì£¼ì‹ + ETF ì „ì²´ ì¡°íšŒ"""
    if fdr is None:
        print("Error: FinanceDataReaderê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.", file=sys.stderr)
        return {"stocks": {}, "etfs": {}}

    cached = load_cache()
    if cached and "stocks" in cached and "etfs" in cached:
        return {"stocks": cached["stocks"], "etfs": cached["etfs"]}

    result = {"stocks": {}, "etfs": {}}

    try:
        # ì£¼ì‹
        df_stocks = fdr.StockListing('KRX')
        for _, row in df_stocks.iterrows():
            code = str(row['Code']).zfill(6)
            name = row['Name']
            result["stocks"][name] = code

        # ETF
        df_etf = fdr.StockListing('ETF/KR')
        for _, row in df_etf.iterrows():
            code = str(row['Symbol']).zfill(6)
            name = row['Name']
            result["etfs"][name] = code

        save_cache(result)
        return result
    except Exception as e:
        print(f"Error fetching listings: {e}", file=sys.stderr)
        return result


def search_index(query: str) -> list[tuple[str, str, str]]:
    """ì§€ìˆ˜ ê²€ìƒ‰"""
    query_lower = query.lower()
    results = []

    # ì§ì ‘ ë§¤ì¹­
    if query_lower in INDICES:
        info = INDICES[query_lower]
        results.append((info["name"], info["symbol"], "ì§€ìˆ˜"))
        return results

    # ë¶€ë¶„ ë§¤ì¹­
    for key, info in INDICES.items():
        if query_lower in key or query_lower in info["name"].lower():
            if (info["name"], info["symbol"], "ì§€ìˆ˜") not in results:
                results.append((info["name"], info["symbol"], "ì§€ìˆ˜"))

    return results


def search_all(query: str, limit: int = 20, search_type: str = "all") -> list[tuple[str, str, str]]:
    """í†µí•© ê²€ìƒ‰ (ì£¼ì‹ + ETF + ì§€ìˆ˜)"""
    query = query.strip()
    results = []

    # ì§€ìˆ˜ ê²€ìƒ‰
    if search_type in ["all", "index"]:
        index_results = search_index(query)
        results.extend(index_results)

    # ì£¼ì‹/ETF ê²€ìƒ‰
    if search_type in ["all", "stock", "etf"]:
        data = fetch_all_listings()
        stocks = data.get("stocks", {}) if search_type in ["all", "stock"] else {}
        etfs = data.get("etfs", {}) if search_type in ["all", "etf"] else {}

        # ì¢…ëª©ì½”ë“œë¡œ ê²€ìƒ‰
        if query.isdigit():
            code = query.zfill(6)
            for name, c in stocks.items():
                if c == code:
                    results.append((name, code, "ì£¼ì‹"))
                    break
            for name, c in etfs.items():
                if c == code:
                    results.append((name, code, "ETF"))
                    break

        # ì¢…ëª©ëª…ìœ¼ë¡œ ê²€ìƒ‰
        else:
            query_lower = query.lower()

            # ì •í™•íˆ ì¼ì¹˜
            for name, code in stocks.items():
                if query_lower == name.lower():
                    results.append((name, code, "ì£¼ì‹"))
            for name, code in etfs.items():
                if query_lower == name.lower():
                    results.append((name, code, "ETF"))

            # ì‹œì‘í•˜ëŠ” ê²ƒ
            for name, code in stocks.items():
                if name.lower().startswith(query_lower) and (name, code, "ì£¼ì‹") not in results:
                    results.append((name, code, "ì£¼ì‹"))
            for name, code in etfs.items():
                if name.lower().startswith(query_lower) and (name, code, "ETF") not in results:
                    results.append((name, code, "ETF"))

            # í¬í•¨í•˜ëŠ” ê²ƒ
            for name, code in stocks.items():
                if query_lower in name.lower() and (name, code, "ì£¼ì‹") not in results:
                    results.append((name, code, "ì£¼ì‹"))
            for name, code in etfs.items():
                if query_lower in name.lower() and (name, code, "ETF") not in results:
                    results.append((name, code, "ETF"))

    return results[:limit]


def display_results(query: str, results: list[tuple[str, str, str]]) -> None:
    """ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥"""
    if not results:
        print(f"'{query}' ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return

    print(f"ğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê±´)")
    print("â”" * 50)
    for name, code, type_ in results:
        type_emoji = {"ì£¼ì‹": "ğŸ“ˆ", "ETF": "ğŸ“Š", "ì§€ìˆ˜": "ğŸ“‰"}.get(type_, "")
        print(f"  {type_emoji} [{type_}] {name}: {code}")


def main():
    parser = argparse.ArgumentParser(description="KRX ì¢…ëª©/ETF/ì§€ìˆ˜ ê²€ìƒ‰")
    parser.add_argument("query", help="ì¢…ëª©ëª…, ì¢…ëª©ì½”ë“œ, ë˜ëŠ” ì§€ìˆ˜ëª…")
    parser.add_argument("--type", "-t", choices=["all", "stock", "etf", "index"], default="all",
                        help="ê²€ìƒ‰ ìœ í˜• (all: ì „ì²´, stock: ì£¼ì‹, etf: ETF, index: ì§€ìˆ˜)")
    parser.add_argument("--limit", "-l", type=int, default=20, help="ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 20)")
    parser.add_argument("--json", action="store_true", help="JSON í˜•ì‹ ì¶œë ¥")
    parser.add_argument("--refresh", action="store_true", help="ìºì‹œ ìƒˆë¡œê³ ì¹¨")
    args = parser.parse_args()

    # ìºì‹œ ìƒˆë¡œê³ ì¹¨
    if args.refresh and CACHE_FILE.exists():
        CACHE_FILE.unlink()

    results = search_all(args.query, args.limit, args.type)

    if args.json:
        output = [{"name": name, "code": code, "type": type_} for name, code, type_ in results]
        print(json.dumps(output, indent=2, ensure_ascii=False))
    else:
        display_results(args.query, results)


if __name__ == "__main__":
    main()
